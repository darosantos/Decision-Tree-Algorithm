{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project D4.5</h1>\n",
    "<p>Este projeto <i>jupyter notebook</i> é uma forma de mostrar a implementação de cada arquivo para o algoritmo C4.5</p>\n",
    "<p>Ao contrário do arquivo de definição e exploração este arquivo se concentra em ter somente código python</p>\n",
    "<p>Cada célula seria um arquivo a estar no mesmo diretório e a indicação do nome deste arquivo esta no comentário junto com uma breve descrição</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Filename: DT_DataStructure.py\n",
    "# Description: Contém a definição dos tipos de dados utilizados no projeto\n",
    "###\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Alias for type\n",
    "DataFrequency = Dict[str, Any]\n",
    "\n",
    "Frequency = List[DataFrequency]\n",
    "\n",
    "DataIdColumn = List[str]\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)\n",
    "    \n",
    "                \n",
    "class StructNode(Struct):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Filename: DT_Util.py\n",
    "# Description: Contém funções utilizadas pelas classes, mas que não fazem parte do comportamentpo das classes\n",
    "###\n",
    "\n",
    "# import DT_DataStructure.py\n",
    "\n",
    "class Util:\n",
    "    \"\"\"Class Util\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Filename: DT_DecisionTree.py\n",
    "# Description: Contém a classe para arvore de decisão\n",
    "###\n",
    "\n",
    "# import DT_DataStructure\n",
    "import logging\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"Decision Tree Class\"\"\"\n",
    "    def __init__(self, data_trainning, column_label_class: str, target_class: str):\n",
    "        from pandas import DataFrame\n",
    "        \n",
    "        if not isinstance(data_trainning, DataFrame):\n",
    "            raise TypeError('Expected value should descend from pandas.core.frame.DataFrame')\n",
    "        self.__data_trainning = data_trainning.iloc[:,0:]\n",
    "        \n",
    "        self.__total_instances = self.__data_trainning.shape[0]\n",
    "        \n",
    "        #if (id_column_class >= data_trainning.shape[1]):\n",
    "        #    raise TypeError('Expected value integer in limit for data frame')\n",
    "        #self.__id_column_class = id_column_class\n",
    "        \n",
    "        self.__entropy_global = 0.0\n",
    "        \n",
    "        self.__root_tree = None\n",
    "        \n",
    "        self.__logger = True\n",
    "        \n",
    "        self.__target_class = target_class\n",
    "        \n",
    "        self.__column_label_class = column_label_class\n",
    "        \n",
    "        self.__columns = None\n",
    "        \n",
    "        self.__id_classifier = 'ClassifierTree'\n",
    "        \n",
    "        # self.__type_discret = (str)\n",
    "        \n",
    "        # self.__type_continuous = ('int', 'float')\n",
    "        \n",
    "        self.__method_continuos_supported = ('media', 'mediana', 'quantil', 'moda')\n",
    "        \n",
    "        self.__method_continuos_selected = 'media'\n",
    "        \n",
    "        self.__method_continuos_args = {'quantil': 0.5}\n",
    "\n",
    "        \n",
    "    def __entropy(self, class_positive: int, class_negative: int) -> float:\n",
    "        from math import log2\n",
    "        \"\"\"\n",
    "            Esta função calcula a entropia total de um conjunto de dados, observe \n",
    "                que o valor da entropia varia em função da precisão de ponto flutuante de python\n",
    "            Input:  class_positive = numero de instâncias com classe positiva\n",
    "                    class_negative = número de instâncias com classe negativa\n",
    "            Output: (float) que representa a entropia total do conjunto\n",
    "        \"\"\"\n",
    "        if (class_positive < 0) or (class_negative < 0):\n",
    "            return -1\n",
    "        if (class_positive == 0) or (class_negative == 0):\n",
    "            return 0\n",
    "        total_instance = class_positive + class_negative\n",
    "        p = (class_positive/total_instance) * log2(class_positive/total_instance)\n",
    "        q = (class_negative/total_instance) * log2(class_negative/total_instance)\n",
    "        r__entropy = (-1 * p) - q\n",
    "        \n",
    "        msg = \"[Entropy for calculate]:\\tClass positive = {}\\tClass negative = {}\\tTotal instances = {}\\tEntropy = {}\"\n",
    "        msg = msg.format(class_positive, class_negative, (class_positive+class_negative), r__entropy)\n",
    "        logging.debug(msg)\n",
    "        \n",
    "        return r__entropy\n",
    "    \n",
    "    \n",
    "    def __prepareCalcEntropy(self, ref_trainning: list) -> float:\n",
    "        \"\"\"\n",
    "             Esta função lida com os dados do subconjunto para o cálculo da entropia, desta maneira \n",
    "                 de um lado temos a função que calcula a entropia e de outro uma função que prepara\n",
    "                 os dados para este cálculo\n",
    "            Input:  ref_trainning = uma lista com os nomes das colunas (subconjunto) para o cálculo\n",
    "                        da entropia\n",
    "            Output: (float) que representa a entropia total do conjunto\n",
    "        \"\"\"\n",
    "        if (not self.__column_label_class in ref_trainning):\n",
    "            ref_trainning.append(self.__column_label_class)\n",
    "        \n",
    "        msg = \"[Prepare calc entropy]:\\tColumn Label Trainning = {}\"\n",
    "        msg = msg.format(self, ref_trainning)\n",
    "        logging.debug(msg)\n",
    "        \n",
    "        df_selected = self.__data_trainning.loc[:,ref_trainning]\n",
    "        total_intances = self.__data_trainning[self.__column_label_class].count()\n",
    "        mask = self.__column_label_class + ' == ' + '\"' + self.__target_class + '\"'\n",
    "        class_positive = df_selected.query(mask)[self.__column_label_class].count()\n",
    "        class_negative = total_intances - class_positive\n",
    "        r__prepare_calc_entropy = self.__entropy(class_positive, class_negative)\n",
    "        \n",
    "        return r__prepare_calc_entropy\n",
    "        \n",
    "        \n",
    "    def __gaugeStopRecursion(self, ref_trainning: list) -> bool:\n",
    "        \"\"\" \n",
    "            Esta função determina quando a recursividade da arvore deve parar para a expansão\n",
    "                Neste caso termina caso seja o úlitmo nó da lista\n",
    "            Input: Dados de treinamento\n",
    "            Output: (Bool) True = Stop, False = Continue\n",
    "        \"\"\"\n",
    "        \n",
    "        msg = \"[Gauge Stop Recursion]:\\t Label Trainning = {}\"\n",
    "        msg = msg.format(ref_trainning)\n",
    "        logging.debug(msg)\n",
    "        \n",
    "        if len(ref_trainning) == 0:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def __gainInformation(self, frequencies: Frequency, total_instances: int) -> float:\n",
    "        \"\"\"\n",
    "            Esta função calcula o ganho de informação de um conjunto de dados, observe \n",
    "                que o valor do ganho de informação varia em função da precisão de ponto \n",
    "                flutuante de python\n",
    "            Input:  class_positive = numero de instâncias com classe positiva\n",
    "                    class_negative = número de instâncias com classe negativa\n",
    "                    frequencies = uma lista de dicionário que representa os dados do conjunto\n",
    "            Output: (float) que representa o ganho de informação total do conjunto\n",
    "        \"\"\"\n",
    "        \n",
    "        msg = '[Gain Information]:\\tFrequencies = {}\\t Total instances = {}'\n",
    "        msg = msg.format(frequencies, total_instances)\n",
    "        logging.debug(msg)\n",
    "        \n",
    "        gain_local = 0\n",
    "        \n",
    "        for frequency in frequencies:        \n",
    "            frequency_entropy = self.__entropy(frequency['class_positive'], frequency['class_negative'])\n",
    "            frequency_relative = frequency['class_positive'] + frequency['class_negative']\n",
    "            gain_local += (frequency_relative / total_instances) * frequency_entropy\n",
    "\n",
    "        r__gainInformation =  self.__entropy_global - gain_local\n",
    "        \n",
    "        msg = \"[Gain Information]\\tEntropy Global = {}\\tEntropy Local = {}\\tGain Information = {}\"\n",
    "        msg = msg.format(self.__entropy_global, gain_local, r__gainInformation)\n",
    "        logging.debug(msg)\n",
    "        \n",
    "        return r__gainInformation\n",
    "    \n",
    "    \n",
    "    def __get_point_cut(self, df_column) -> float:\n",
    "        \"\"\"\n",
    "            Esta função calcula o ponto de divisão em uma série de acordo com as pŕedefinições da classe\n",
    "            Input:  df_column = Coluna do dataframe\n",
    "            Output: (float) que representa o valor do ponto de divisão\n",
    "        \"\"\"\n",
    "        r__point_cut = 0\n",
    "        if (self.__method_continuos_selected == 'media'):\n",
    "            r__point_cut = df_column.mean()\n",
    "        elif (self.__method_continuos_selected == 'mediana'):\n",
    "            r__point_cut = df_column.median()\n",
    "        elif (self.__method_continuos_selected == 'quantil'):\n",
    "            r__point_cutter = df_column.quantile(q=self.__method_continuos_args['quantil'])\n",
    "        elif (self.__method_continuos_selected == 'moda'):\n",
    "            r__point_cut = df_column.mode()\n",
    "        else:\n",
    "            r__point_cut = df_column.mean()\n",
    "        \n",
    "        return r__point_cut;\n",
    "    \n",
    "    \n",
    "    def __mountFrequencySeriesDiscrete(self, df_work, column_name: str) -> list:\n",
    "        \"\"\"\n",
    "            Esta função monta a estrutura de dados de uma série discreta para ser usado no cálculo\n",
    "                de ganho de informação\n",
    "            Input:  df_work = DataFrame formado pela coluna de dados e pela coluna de classes\n",
    "                    column_name = nome da coluna de dados do dataframe\n",
    "            Output: (list) uma lista de dicionário com a estrutura (value, class_positive, class_negative)\n",
    "        \"\"\"\n",
    "        column_frequency = []\n",
    "        partitions = list(df_work[column_name].unique())\n",
    "        for partition in partitions:\n",
    "            mask_up = column_name + '==' + '\"' + partition + '\"'\n",
    "            df_up = df_work.query(mask_up)\n",
    "            total_instances = df_up[column_name].count()\n",
    "            mask_target = self.__column_label_class + ' == ' + '\"' + self.__target_class + '\"'\n",
    "            class_positive = df_up.query(mask_target)[column_name].count()\n",
    "            class_negative = total_instances - class_positive\n",
    "            column_frequency.append({'value': partition, \n",
    "                                     'class_positive': class_positive, \n",
    "                                     'class_negative': class_negative\n",
    "                                    })\n",
    "        return column_frequency\n",
    "        \n",
    "        \n",
    "        \n",
    "    def __mountFrequencySeriesContinuos(self, df_work, column_name: str) -> list:\n",
    "        \"\"\"\n",
    "            Esta função monta a estrutura de dados de uma série continua para ser usada no cálculo\n",
    "                de ganho de informação\n",
    "            Input:  df_work = DataFrame formado pela coluna de dados e pela coluna de classes\n",
    "                    column_name = nome da coluna de dados do dataframe\n",
    "            Output: (list) uma lista de dicionário com a estrutura (value, class_positive, class_negative)\n",
    "        \"\"\"\n",
    "        point_cut = self.__get_point_cut(df_work[column_name])\n",
    "        column_frequency = []\n",
    "        for unique_partition in ['<=', '>']:\n",
    "            mask_up = column_name + unique_partition + str(point_cut)\n",
    "            df_up = df_work.query(mask_up)\n",
    "            total_instances = df_up[column_name].count()\n",
    "            mask_target = self.__column_label_class + ' == ' + '\"' + self.__target_class + '\"'\n",
    "            class_positive = df_up.query(mask_target)[column_name].count()\n",
    "            class_negative = total_instances - class_positive\n",
    "            column_frequency.append({'value': unique_partition, \n",
    "                                     'class_positive': class_positive, \n",
    "                                     'class_negative': class_negative\n",
    "                                    })\n",
    "        return column_frequency\n",
    "                    \n",
    "        \n",
    "    def __getFrequency(self, column_name: str) -> list:\n",
    "        type_column = type(self.__data_trainning[column_name][0])\n",
    "        df_work = self.__data_trainning.loc[:,[self.__column_label_class, column_name]]\n",
    "        total_instances_work = df_work[column_name].count()\n",
    "        column_frequency = []\n",
    "        if (type_column != str):\n",
    "            column_frequency = self.__mountFrequencySeriesContinuos(df_work, column_name)\n",
    "        else:\n",
    "            column_frequency = self.__mountFrequencySeriesDiscrete(df_work, column_name)\n",
    "        return column_frequency\n",
    "\n",
    "                \n",
    "    # Deveria haver um parametro column_predecessor para que os dados fossem \n",
    "    # filtrados com base no nó anterior cujos valores determinam a classe\n",
    "    def __splitDecisionTree(self, columns_trainning: list) -> str:\n",
    "        r_split = {}\n",
    "        \n",
    "        msg = \"[Split Decision Tree]\\tColumn Trainning = {}\"\n",
    "        msg = msg.format(columns_trainning)\n",
    "        logging.debug(msg)\n",
    "            \n",
    "        for column in columns_trainning:\n",
    "            \n",
    "            msg = \"[Split Decision Tree]\\tColumn = {}\"\n",
    "            msg = msg.format(column)\n",
    "            logging.debug(msg)\n",
    "            \n",
    "            total_instances = self.__data_trainning[column].count()\n",
    "            column_frequency = self.__getFrequency(column)\n",
    "            r_split[column] = self.__gainInformation(column_frequency, total_instances)\n",
    "        \n",
    "        msg = \"[Split Decision Tree]\\tGain Information = {}\"\n",
    "        msg = msg.format(r_split)\n",
    "        logging.debug(msg)\n",
    "            \n",
    "        point_division_label = max(r_split, key=r_split.get)\n",
    "        \n",
    "        return point_division_label\n",
    "    \n",
    "    \n",
    "    def __makingRating(self, column_name: str) -> dict:\n",
    "        column_frequency = self.__getFrequency(column_name)\n",
    "        rating = {'value_positive': [], 'value_negative': []}\n",
    "        for frequency in column_frequency:\n",
    "            if (frequency['class_positive'] > frequency['class_negative']):\n",
    "                rating['value_positive'].append(frequency['value'])\n",
    "            else:\n",
    "                rating['value_negative'].append(frequency['value'])\n",
    "                \n",
    "        return rating\n",
    "        \n",
    "        \n",
    "    # @ TODO: Reve a criação do nó para o caso de parada de recursão\n",
    "    def __gender(self, ref_trainning: list) -> Any:\n",
    "        \"\"\"\n",
    "            Esta função gera recursivamente a arvore de decisão\n",
    "            Input: Dados de treinamento\n",
    "            Output: (Struct) a arvore de decisão\n",
    "        \"\"\"\n",
    "        if (self.__gaugeStopRecursion(ref_trainning)):\n",
    "            return None;\n",
    "        \n",
    "        if (len(ref_trainning) == 1):\n",
    "            node_label = ref_trainning[0]\n",
    "            node_codition = self.__makingRating(node_label)\n",
    "            r__leaf_end = StructNode(label = node_label, \n",
    "                                     test_condition = node_codition,\n",
    "                                     classification = self.__target_class,\n",
    "                                     leaf = True)\n",
    "            print('Aprovado na parada!')\n",
    "            return r__leaf_end\n",
    "        else:\n",
    "            print('Reprovado na parada!')\n",
    "        # else\n",
    "        print('Gender = ' + str(ref_trainning))\n",
    "        pointDivisionList = self.__splitDecisionTree(ref_trainning)\n",
    "        node_codition = self.__makingRating(pointDivisionList)\n",
    "        left_partition = ref_trainning[:ref_trainning.index(pointDivisionList)]\n",
    "        right_partition = ref_trainning[ref_trainning.index(pointDivisionList)+1:]\n",
    "        \n",
    "        treeTrunk = StructNode(label = pointDivisionList,\n",
    "                               test_condition = node_codition,\n",
    "                               classification = self.__target_class,\n",
    "                               leaf = False,\n",
    "                               children_left = None,\n",
    "                               children_right = None)\n",
    "        \n",
    "        treeTrunk.children_left = self.__gender(left_partition)\n",
    "        treeTrunk.children_right = self.__gender(right_partition)\n",
    "        \n",
    "        return treeTrunk\n",
    "        \n",
    "        \n",
    "    def build(self) -> None:\n",
    "        \"\"\" Esta função inicia o processo para criar a arvore de decisão\"\"\"\n",
    "        if self.__logger:\n",
    "            logging.basicConfig(filename=self.__getNameLog(),\n",
    "                                level= logging.DEBUG, \n",
    "                                format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "            \n",
    "        column_df = list(self.__data_trainning.columns)\n",
    "        self.__columns = column_df\n",
    "        self.__entropy_global = self.__prepareCalcEntropy(column_df)\n",
    "        \n",
    "        column_df.pop(column_df.index(self.__column_label_class))\n",
    "        self.__root_tree = self.__gender(column_df)\n",
    "        print('Pronto!')\n",
    "        \n",
    "        \n",
    "    def debugTree(self, node):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def __preparePrint(self, node, acm: float):\n",
    "        if (node == None):\n",
    "            return\n",
    "        \n",
    "        return data_print\n",
    "        \n",
    "        \n",
    "    def showGraph(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import squarify\n",
    "        \n",
    "        column_df = list(self.__data_trainning.columns)\n",
    "        acm = (len(column_df) - 1) * 100\n",
    "        plot_label = []\n",
    "        self.__preparePrint(self.__root_tree, acm)\n",
    "        #print(self.__root_tree)\n",
    "        print(plot_label)\n",
    "        \n",
    "        \n",
    "    def setProperties(propertie: str, value: Any) -> None:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def getProperties(propertie: str) -> Any:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def __getNameLog(self) -> str:\n",
    "        import time as lib_tm\n",
    "        coded_time = str(lib_tm.localtime().tm_hour) + '_' + str(lib_tm.localtime().tm_min) + '_' + str(lib_tm.localtime().tm_sec)\n",
    "        filename = self.__id_classifier + coded_time + '.log'\n",
    "        return filename\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Abaixo esta a seção de testes utilizada</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_bc = pd.read_csv('breast-cancer.data')\n",
    "labels = ['classe', 'age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
    "df_bc = pd.read_csv('breast-cancer.data', names=labels)\n",
    "df_bc.to_csv('breast-cancer-edited', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8778446951746506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': 0.010605956535614025,\n",
       " 'menopause': 0.0020016149737116518,\n",
       " 'inv_nodes': 0.06899508808988608,\n",
       " 'deg_malig': None}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = DecisionTree(df_bc, 'classe', 'no-recurrence-events')\n",
    "a.build()\n",
    "# ['classe', 'age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
    "columns = ['age', 'menopause', 'inv_nodes', 'deg_malig']\n",
    "a.splitDecisionTree(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8778446951746506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': 0.010605956535614136,\n",
       " 'menopause': 0.0020016149737116518,\n",
       " 'inv_nodes': 0.06899508808988608,\n",
       " 'deg_malig': 0.0754168448376169}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = DecisionTree(df_bc, 'classe', 'no-recurrence-events')\n",
    "a.build()\n",
    "# ['classe', 'age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
    "columns = ['age', 'menopause', 'inv_nodes', 'deg_malig']\n",
    "a.splitDecisionTree(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deg_malig'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = DecisionTree(df_bc, 'classe', 'no-recurrence-events')\n",
    "a.build()\n",
    "# ['classe', 'age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
    "columns = ['age', 'menopause', 'inv_nodes', 'deg_malig']\n",
    "a.splitDecisionTree(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'menopause', 'tumor_size', 'inv_nodes']\n",
      "['deg_malig', 'breast', 'breast_quad', 'irradiat']\n"
     ]
    }
   ],
   "source": [
    "# self.__data_trainning.loc[:,ref_trainning]\n",
    "# [x for x in vec if x >= 0]\n",
    "ref_tranning = ['age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
    "#left_partition = [column for column in ref_tranning if column != 'node_caps']\n",
    "left_partition = ref_tranning[:ref_tranning.index('node_caps')]\n",
    "right_partition = ref_tranning[ref_tranning.index('node_caps')+1:]\n",
    "print(left_partition)\n",
    "print(right_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reprovado na parada!\n",
      "Gender = ['age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
      "Reprovado na parada!\n",
      "Gender = ['age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps']\n",
      "Reprovado na parada!\n",
      "Gender = ['age', 'menopause', 'tumor_size']\n",
      "Reprovado na parada!\n",
      "Gender = ['age', 'menopause']\n",
      "Aprovado na parada!\n",
      "Aprovado na parada!\n",
      "Reprovado na parada!\n",
      "Gender = ['breast', 'breast_quad', 'irradiat']\n",
      "Reprovado na parada!\n",
      "Gender = ['breast', 'breast_quad']\n",
      "Aprovado na parada!\n",
      "Pronto!\n"
     ]
    }
   ],
   "source": [
    "a = DecisionTree(df_bc, 'classe', 'no-recurrence-events')\n",
    "a.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StructNode' object has no attribute 'children_left'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-f7da0e7bc184>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-45-d28c5759487e>\u001b[0m in \u001b[0;36mshowGraph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0macm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_df\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[0mplot_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__root_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m         \u001b[1;31m#print(self.__root_tree)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-d28c5759487e>\u001b[0m in \u001b[0;36m__preparePrint\u001b[1;34m(self, node, acm)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_representation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-d28c5759487e>\u001b[0m in \u001b[0;36m__preparePrint\u001b[1;34m(self, node, acm)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_representation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-d28c5759487e>\u001b[0m in \u001b[0;36m__preparePrint\u001b[1;34m(self, node, acm)\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_representation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-d28c5759487e>\u001b[0m in \u001b[0;36m__preparePrint\u001b[1;34m(self, node, acm)\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata_print\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-d28c5759487e>\u001b[0m in \u001b[0;36m__preparePrint\u001b[1;34m(self, node, acm)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_representation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m             \u001b[0mdata_print\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__preparePrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_right\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StructNode' object has no attribute 'children_left'"
     ]
    }
   ],
   "source": [
    "a.showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
