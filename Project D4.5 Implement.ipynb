{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project D4.5</h1>\n",
    "<p>Este projeto <i>jupyter notebook</i> é uma forma de mostrar a implementação de cada arquivo para o algoritmo C4.5</p>\n",
    "<p>Ao contrário do arquivo de definição e exploração este arquivo se concentra em ter somente código python</p>\n",
    "<p>Cada célula seria um arquivo a estar no mesmo diretório e a indicação do nome deste arquivo esta no comentário junto com uma breve descrição</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Filename: DT_DataStructure.py\n",
    "# Description: Contém a definição dos tipos de dados utilizados no projeto\n",
    "###\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Alias for type\n",
    "DataFrequency = Dict[str, Any]\n",
    "\n",
    "Frequency = List[DataFrequency]\n",
    "\n",
    "DataIdColumn = List[str]\n",
    "\n",
    "class Struct:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "class StructNode(Struct):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Filename: DT_Util.py\n",
    "# Description: Contém funções utilizadas pelas classes, mas que não fazem parte do comportamentpo das classes\n",
    "###\n",
    "\n",
    "# import DT_DataStructure.py\n",
    "\n",
    "class Util:\n",
    "    \"\"\"Class Util\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Float' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d22737159924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# import DT_DataStructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"\"\"Decision Tree Class\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_trainning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_label_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-d22737159924>\u001b[0m in \u001b[0;36mDecisionTree\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_point_cut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_column\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m    128\u001b[0m             \u001b[0mEsta\u001b[0m \u001b[0mfunção\u001b[0m \u001b[0mcalcula\u001b[0m \u001b[0mo\u001b[0m \u001b[0mponto\u001b[0m \u001b[0mde\u001b[0m \u001b[0mdivisão\u001b[0m \u001b[0mem\u001b[0m \u001b[0muma\u001b[0m \u001b[0msérie\u001b[0m \u001b[0mde\u001b[0m \u001b[0macordo\u001b[0m \u001b[0mcom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpŕedefinições\u001b[0m \u001b[0mda\u001b[0m \u001b[0mclasse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Float' is not defined"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# Filename: DT_DecisionTree.py\n",
    "# Description: Contém a classe para arvore de decisão\n",
    "###\n",
    "\n",
    "# import DT_DataStructure\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"Decision Tree Class\"\"\"\n",
    "    def __init__(self, data_trainning, column_label_class: str, target_class: str):\n",
    "        from pandas import DataFrame\n",
    "        \n",
    "        if not isinstance(data_trainning, DataFrame):\n",
    "            raise TypeError('Expected value should descend from pandas.core.frame.DataFrame')\n",
    "        self.__data_trainning = data_trainning.iloc[:,0:]\n",
    "        \n",
    "        self.__total_instances = self.__data_trainning.shape[0]\n",
    "        \n",
    "        #if (id_column_class >= data_trainning.shape[1]):\n",
    "        #    raise TypeError('Expected value integer in limit for data frame')\n",
    "        #self.__id_column_class = id_column_class\n",
    "        \n",
    "        self.__entropy_global = 0.0\n",
    "        \n",
    "        self.__root_tree = None\n",
    "        \n",
    "        self.__logger = ''\n",
    "        \n",
    "        self.__target_class = target_class\n",
    "        \n",
    "        self.__column_label_class = column_label_class\n",
    "        \n",
    "        self.__columns = None\n",
    "        \n",
    "        # self.__type_discret = (str)\n",
    "        \n",
    "        # self.__type_continuous = ('int', 'float')\n",
    "        \n",
    "        self.__method_continuos_supported = ('media', 'mediana', 'quantil', 'moda')\n",
    "        \n",
    "        self.__method_continuos_selected = 'media'\n",
    "        \n",
    "        self.__method_continuos_args = {'quantil': 0.5}\n",
    "\n",
    "        \n",
    "    def __entropy(self, class_positive: int, class_negative: int) -> float:\n",
    "        from math import log2\n",
    "        \"\"\"\n",
    "            Esta função calcula a entropia total de um conjunto de dados, observe \n",
    "                que o valor da entropia varia em função da precisão de ponto flutuante de python\n",
    "            Input:  class_positive = numero de instâncias com classe positiva\n",
    "                    class_negative = número de instâncias com classe negativa\n",
    "            Output: (float) que representa a entropia total do conjunto\n",
    "        \"\"\"\n",
    "        if (class_positive < 0) or (class_negative < 0):\n",
    "            return -1\n",
    "        if (class_positive == 0) or (class_negative == 0):\n",
    "            return 0\n",
    "        total_instance = class_positive + class_negative\n",
    "        p = (class_positive/total_instance) * log2(class_positive/total_instance)\n",
    "        q = (class_negative/total_instance) * log2(class_negative/total_instance)\n",
    "        r__entropy = (-1 * p) - q\n",
    "        \n",
    "        return r__entropy\n",
    "    \n",
    "    \n",
    "    def __prepareCalcEntropy(self, ref_trainning: list) -> float:\n",
    "        \"\"\"\n",
    "             Esta função lida com os dados do subconjunto para o cálculo da entropia, desta maneira \n",
    "                 de um lado temos a função que calcula a entropia e de outro uma função que prepara\n",
    "                 os dados para este cálculo\n",
    "            Input:  ref_trainning = uma lista com os nomes das colunas (subconjunto) para o cálculo\n",
    "                        da entropia\n",
    "            Output: (float) que representa a entropia total do conjunto\n",
    "        \"\"\"\n",
    "        if (not self.__column_label_class in ref_trainning):\n",
    "            ref_trainning.append(self.__column_label_class)\n",
    "        \n",
    "        df_selected = self.__data_trainning.loc[:,ref_trainning]\n",
    "        total_intances = self.__data_trainning[self.__column_label_class].count()\n",
    "        mask = self.__column_label_class + ' == ' + '\"' + self.__target_class + '\"'\n",
    "        class_positive = df_selected.query(mask)[self.__column_label_class].count()\n",
    "        class_negative = total_intances - class_positive\n",
    "        r__prepare_calc_entropy = self.__entropy(class_positive, class_negative)\n",
    "        \n",
    "        return r__prepare_calc_entropy\n",
    "        \n",
    "        \n",
    "    def __gaugeStopRecursion(ref_trainning: list) -> bool:\n",
    "        \"\"\" \n",
    "            Esta função determina quando a recursividade da arvore deve parar para a expansão\n",
    "                Neste caso termina caso seja o úlitmo nó da lista\n",
    "            Input: Dados de treinamento\n",
    "            Output: (Bool) True = Stop, False = Continue\n",
    "        \"\"\"\n",
    "        if len(ref_trainning) == 1:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def __gainInformation(self, frequencies: Frequency, total_instances: int) -> float:\n",
    "        \"\"\"\n",
    "            Esta função calcula o ganho de informação de um conjunto de dados, observe \n",
    "                que o valor do ganho de informação varia em função da precisão de ponto \n",
    "                flutuante de python\n",
    "            Input:  class_positive = numero de instâncias com classe positiva\n",
    "                    class_negative = número de instâncias com classe negativa\n",
    "                    frequencies = uma lista de dicionário que representa os dados do conjunto\n",
    "            Output: (float) que representa o ganho de informação total do conjunto\n",
    "        \"\"\"\n",
    "        gain_local = 0\n",
    "        \n",
    "        for frequency in frequencies:        \n",
    "            frequency_entropy = self.__entropy(frequency['class_positive'], frequency['class_negative'])\n",
    "            frequency_relative = frequency['class_positive'] + frequency['class_negative']\n",
    "            gain_local += (frequency_relative / total_instances) * frequency_entropy\n",
    "\n",
    "        r__gainInformation =  self.__entropy_global - gain_local\n",
    "        return r__gainInformation\n",
    "    \n",
    "    \n",
    "    def __get_point_cut(self, df_column) -> float:\n",
    "        \"\"\"\n",
    "            Esta função calcula o ponto de divisão em uma série de acordo com as pŕedefinições da classe\n",
    "            Input:  df_column = Coluna do dataframe\n",
    "            Output: (float) que representa o valor do ponto de divisão\n",
    "        \"\"\"\n",
    "        r__point_cut = 0\n",
    "        if (self.__method_continuos_selected == 'media'):\n",
    "            r__point_cut = df_column.mean()\n",
    "        elif (self.__method_continuos_selected == 'mediana'):\n",
    "            r__point_cut = df_column.median()\n",
    "        elif (self.__method_continuos_selected == 'quantil'):\n",
    "            r__point_cutter = df_column.quantile(q=self.__method_continuos_args['quantil'])\n",
    "        elif (self.__method_continuos_selected == 'moda'):\n",
    "            r__point_cut = df_column.mode()\n",
    "        else:\n",
    "            r__point_cut = df_column.mean()\n",
    "        \n",
    "        return r__point_cut;\n",
    "    \n",
    "    \n",
    "    def prepareCalcGainInformation(self, partitions: list, df_work ) -> list:\n",
    "        column_frequency = []\n",
    "        for partition in partitions:\n",
    "            mask_up = column + ' == ' + '\"' + partition + '\"'\n",
    "            df_uv = df_work.query(mask_uv)\n",
    "            total_instances = df_uv[column].count()\n",
    "            mask_target = self.__column_label_class + ' == ' + '\"' + self.__target_class + '\"'\n",
    "            class_positive = df_uv.query(mask_target)[column].count()\n",
    "            class_negative = total_instances - class_positive\n",
    "            column_frequency.append({'value': unique_value, \n",
    "                                     'class_positive': class_positive, \n",
    "                                     'class_negative': class_negative\n",
    "                                    })\n",
    "            return column_frequency\n",
    "        \n",
    "        \n",
    "    # Deveria haver um parametro column_predecessor para que os dados fossem \n",
    "    # filtrados com base no nó anterior cujos valores determinam a classe\n",
    "    def splitDecisionTree(self, columns_trainning: DataIdColumn) -> None:\n",
    "        r_split = {}\n",
    "        \n",
    "        print(self.__entropy_global)\n",
    "        \n",
    "        for column in columns_trainning:\n",
    "            type_column = type(self.__data_trainning[column][0])\n",
    "            df_work = self.__data_trainning.loc[:,[self.__column_label_class, column]]\n",
    "            total_instances_work = df_work[column].count()\n",
    "            if ( type_column == str):\n",
    "                column_unique_value = list(df_work[column].unique())\n",
    "                column_frequency = []\n",
    "                for unique_value in column_unique_value:\n",
    "                    mask_uv = column + ' == ' + '\"' + unique_value + '\"'\n",
    "                    df_uv = df_work.query(mask_uv)\n",
    "                    total_instances = df_uv[column].count()\n",
    "                    mask_target = self.__column_label_class + ' == ' + '\"' + self.__target_class + '\"'\n",
    "                    class_positive = df_uv.query(mask_target)[column].count()\n",
    "                    class_negative = total_instances - class_positive\n",
    "                    column_frequency.append({'value': unique_value, \n",
    "                                             'class_positive': class_positive, \n",
    "                                             'class_negative': class_negative\n",
    "                                            })\n",
    "                r_split[column] = self.__gainInformation(column_frequency, total_instances_work)\n",
    "            else:\n",
    "                point_cut = self.__get_point_cut(df_work[column])\n",
    "                column_frequency = []\n",
    "                for unique_partition in ['<', '>=']:\n",
    "                    mask_up = column + unique_partition + str(point_cut)\n",
    "                    df_up = df_work.query(mask_up)\n",
    "                    total_instances = df_up[column].count()\n",
    "                    mask_target = self.__column_label_class + ' == ' + '\"' + self.__target_class + '\"'\n",
    "                    class_positive = df_up.query(mask_target)[column].count()\n",
    "                    class_negative = total_instances - class_positive\n",
    "                    column_frequency.append({'value': unique_partition, \n",
    "                                             'class_positive': class_positive, \n",
    "                                             'class_negative': class_negative\n",
    "                                            })\n",
    "                    \n",
    "                r_split[column] = self.__gainInformation(column_frequency, total_instances_work) \n",
    "                    \n",
    "        return r_split\n",
    "    \n",
    "    \n",
    "    # @ TODO: Reve a criação do nó para o caso de parada de recursão\n",
    "    def __gender(self, ref_trainning: list) -> Any:\n",
    "        \"\"\"\n",
    "            Esta função gera recursivamente a arvore de decisão\n",
    "            Input: Dados de treinamento\n",
    "            Output: (Struct) a arvore de decisão\n",
    "        \"\"\"\n",
    "        if (self.__gaugeStopRecursion(ref_trainning)):\n",
    "            r__label = ref_trainning[0]\n",
    "            r__classification = self.identifyClass(ref_trainning)\n",
    "            r__test_condition = self.trunkCondition(ref_trainning)\n",
    "            r__leaf_end = StructNode(label = r__label, \n",
    "                                     test_condition = r__test_condition, \n",
    "                                     leaf = True, \n",
    "                                     classification = r__classification)\n",
    "            return r__leaf_end\n",
    "        # else\n",
    "        r__attribPointDivision = self.__splitDecisionTree(ref_trainning)\n",
    "        \n",
    "        \n",
    "    def build(self) -> None:\n",
    "        \"\"\" Esta função inicia o processo para criar a arvore de decisão\"\"\"\n",
    "        column_df = list(self.__data_trainning.columns)\n",
    "        self.__columns = column_df\n",
    "        self.__entropy_global = self.__prepareCalcEntropy(column_df)\n",
    "        \n",
    "        #column_df.pop(self.__id_column_class)\n",
    "        #self.__root_tree = self.__gender(column_df)\n",
    "        \n",
    "        \n",
    "    def __gender_old(ref_trainning: List):\n",
    "        \"\"\"\n",
    "            Esta função gera recursivamente a arvore de decisão\n",
    "            Input: Dados de treinamento\n",
    "            Output: (Struct) a arvore de decisão\n",
    "        \"\"\"\n",
    "        if gaugeStopRecursion(trainningData):\n",
    "            atributo = getAttribFromDataTrainning(trainningData)\n",
    "            classification = identifyClass(trainningData)\n",
    "            tc = trunkCondition(trainningData)\n",
    "            leafEnd = StructNode(label = atributo, test_condition = tc, leaf = True, classification = '')    \n",
    "            return leafEnd\n",
    "        # else\n",
    "        attribPointDivision = splitDecisionTree(trainningData)\n",
    "        tc = trunkCondition(trainningData)\n",
    "        left_partition = copyDataFrame(trainningData, 0, attribPointDivision)\n",
    "        right_partition = copyDataFrame(trainningData, attribPointDivision, -1)\n",
    "        leafRoot = StructNode(label = attribPointDivision, test_condition = tc, leaf = False, left = NULL, right = NULL)\n",
    "\n",
    "        leafRoot.left = genderDecisionTree(left_partition)\n",
    "        leafRoot.right = genderDecisionTree(right_partition)\n",
    "        return leafRoot\n",
    "\n",
    "    \n",
    "    def setProperties(propertie: str, value: Any) -> None:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def getProperties(propertie: str) -> str:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def getAttribFromDataTrainning(trainningData):\n",
    "        \"\"\"Extrai o rótulo de um atributo dos dados de treinamento\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def identifyClass(self, trainningData):\n",
    "        \"\"\"Identifica qual a classe para determinado atributo\"\"\"\n",
    "        pass\n",
    "\n",
    "    def trunkCondition(self, trainningData):\n",
    "        \"\"\"Retorna qual a regra a ser aplicada em determinado tronco da arvore\"\"\"\n",
    "        pass\n",
    "\n",
    "    def copyDataFrame(trainningData, begin, end):\n",
    "        \"\"\"Retorna uma parte do conjunto de dados mapeando em colunas e linhas\"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Abaixo esta a seção de testes utilizada</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_bc = pd.read_csv('breast-cancer.data')\n",
    "labels = ['classe', 'age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
    "df_bc = pd.read_csv('breast-cancer.data', names=labels)\n",
    "df_bc.to_csv('breast-cancer-edited', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8778446951746506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': 0.010605956535614025,\n",
       " 'menopause': 0.0020016149737116518,\n",
       " 'inv_nodes': 0.06899508808988608,\n",
       " 'deg_malig': None}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = DecisionTree(df_bc, 'classe', 'no-recurrence-events')\n",
    "a.build()\n",
    "# ['classe', 'age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
    "columns = ['age', 'menopause', 'inv_nodes', 'deg_malig']\n",
    "a.splitDecisionTree(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8778446951746506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': 0.010605956535614136,\n",
       " 'menopause': 0.0020016149737116518,\n",
       " 'inv_nodes': 0.06899508808988608,\n",
       " 'deg_malig': 0.0754168448376169}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = DecisionTree(df_bc, 'classe', 'no-recurrence-events')\n",
    "a.build()\n",
    "# ['classe', 'age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n",
    "columns = ['age', 'menopause', 'inv_nodes', 'deg_malig']\n",
    "a.splitDecisionTree(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
